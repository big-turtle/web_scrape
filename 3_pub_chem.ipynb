{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Worst Way to Web Scrape: Selenium\n",
    "\n",
    "If you want to feel like a sexy wizard, then use non-headless Selenium and go on a biochemistry journey with me.\n",
    "\n",
    "Brief reminder of what I set out to do. I wanted to understand what the ingrediens on the back of my moisturiser's label *really* mean.\n",
    "\n",
    "Remember the tasks for this project?\n",
    "1. Get a list of the ingredients from the web (done) <br>\n",
    "    1.1. Scrape <br>\n",
    "    1.2. Save the output as a .txt file or create a database\n",
    "2. Access PubChem chemistry database and get the short summaries of each compound/substance (DONE!)\n",
    "3. Read the output by candlelight while taking a bubble bath\n",
    "\n",
    "It's finally time to access the PubChem databases! \n",
    "\n",
    "If you're a part of the .txt file aesthetic crowd, then the following lines will be useful. Here we read in the .txt file we created in the last tootorial (hehe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/path/to/your/file'\n",
    "links_path = filepath + '/ingred_list.txt'\n",
    "ingreds = []\n",
    "# open file and read the content in a list\n",
    "with open(links_path, 'r') as linksfile:\n",
    "    for line in linksfile:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        ingreds.append(currentPlace)\n",
    "\n",
    "linksfile.close()\n",
    "linksfile.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all of the modules. You can use whatever browser you want. I don't remember why, but this time I opted for Firefox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not familiar with PubChem a brief decription would be that it's like Google for chemistry. \n",
    "\n",
    "The next function will get the featured compound result if it's available. If not, the first compound will be selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicks on the featured result\n",
    "#if confirm that featured-result-link exists\n",
    "def get_result(name = ing[n]):\n",
    "    try:\n",
    "        fres = driver.find_element_by_xpath(\"//a[@data-action='featured-result-link']\")\n",
    "        if fres.is_displayed():\n",
    "            fres.click()\n",
    "    \n",
    "    #if no featured link, click on the first search result        \n",
    "    except NoSuchElementException:\n",
    "        print(\"No featured result, looking for the 1st compounds result\")\n",
    "        try:\n",
    "            res = driver.find_element_by_xpath(\"//a[@data-action='result-link']\")\n",
    "            if res.is_displayed():\n",
    "                print(\"1st compounds result selected\")\n",
    "                res.click()\n",
    "                \n",
    "        except NoSuchElementException:\n",
    "            print(\"Invalid search for\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we start the Selenium magic. Keep in mind that you need to download a webdriver, either chromedriver for Google Chrome or gecko driver for Firefox. The driver needs to be either added to your PATH or you can do as I did and add an executable path to your driver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = ingreds[0]\n",
    "ing = ingreds[1:len(ingreds)]\n",
    "n=2\n",
    "\n",
    "gecko_driver = \"/path/to/your/geckodriver\"\n",
    "driver = Firefox(executable_path = gecko_driver)\n",
    "driver.get(\"https://pubchem.ncbi.nlm.nih.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I opted to select elements all throughout this script using XPATHS. Make sure to add some kind of a wait until driver loads the page or at least the stuff you need, otherwise there **will** be an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xpath of the search bar\n",
    "src_xpath = \"//input[contains(@id, 'search_')]\"\n",
    "#waits for the search bar to be loaded\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(ec.visibility_of_element_located((By.XPATH, src_xpath)))\n",
    "\n",
    "src = driver.find_element_by_xpath(src_xpath)\n",
    "src.send_keys(ing[n])\n",
    "src.send_keys(Keys.ENTER)\n",
    "# have to think of something better here\n",
    "driver.implicitly_wait(5)\n",
    "get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've (hopefully) entered a valid compound name that will yield a valid search result.\n",
    "Now the action is happening in a specific compound's page. I've decided that I'm interested in the 'Pharmacology' section. \n",
    "There's a possibility that some more niche compounds will not have a 'Pharmacology' section, so an option is to get the use in manufacturing or something of the sort. I'll get to that later.\n",
    "\n",
    "## Getting text from a page with Selenium\n",
    "Easy: driver.find_element().text <br>\n",
    "Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_xpath = \"//section[contains(@id, 'Pharmacology')]\"\n",
    "\n",
    "try:\n",
    "    wait.until(ec.visibility_of_element_located((By.XPATH, pharm_xpath)))\n",
    "    pharm = driver.find_element_by_xpath(pharm_xpath).text\n",
    "except TimeoutException:\n",
    "    print(\"Took too long to load :(\")\n",
    "except NoSuchElementException:\n",
    "    print(\"No Pharmacology section, looking for the next best thing\")\n",
    "    #try:\n",
    "        #search for use in manufacturing\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we move into the data 'munging' territory. Don't ask me what I think of terms like 'munging' and 'wrangling'. \n",
    "\n",
    "I've decided to specifically get the info from sections pharmacology, mechanism of action and metabolite description. \n",
    "After splitting the huge text block by new lines, we get a list of all of the items that were written in the big 'Pharmacology' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragr = pharm.split(\"\\n\")\n",
    "pharm_paragr = paragr[1:len(paragr)]\n",
    "\n",
    "sections = [\n",
    "        'Pharmacology',\n",
    "        'Mechanism of Action',\n",
    "        'Metabolite Description'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to find where the sections are in the big pharm_paragr list. The following code does just that, returning an index of relevant headings. I made it print out the location of headings probably because I was feeling lonely when I wrote those lines and wanted someone to talk to. There's no need to do that really.\n",
    "\n",
    "If you want to be a stylish script wizard, you can create log files, to which your script writes some status messages throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_nb = []\n",
    "for z in range(len(pharm_paragr)):\n",
    "    for g in sections:\n",
    "        if g in pharm_paragr[z]:\n",
    "            sect_nb.append(z)\n",
    "            print(\"List element nb %i is the section \" %z + pharm_paragr[z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel ashamed that this next section took me THE LONGEST TIME to write, but here it finally is.\n",
    "First we check that there are no weird heading duplicates found in the big Bertha (pharm_paragr).\n",
    "Next we need to find ALL the headings, not only the ones we want to find. Headings luckily start with a number, so we sort by that - if the first element in a string is a number.\n",
    "\n",
    "Then we need to find the range of relevant paragraphs. At this moment the pharm_paragr file is a jumble of headings and paragraphs. So, to find *relevant* paragraphs only, we first find where all of the headings are and then add +1, because the next list item after a heading will be a paragraph.After that, we get the location of where the relevant paragraph ends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sections) == len(sect_nb):\n",
    "    #finds all headings: a string that starts with a number\n",
    "    heads = [pharm_paragr.index(w) for w in pharm_paragr if w[0].isdigit()]\n",
    "    #range of relevant paragraphs\n",
    "    sect_par_index = [heads.index(i) + 1 for i in heads if i in sect_nb]\n",
    "    par_end = [heads[i] for i in sect_par_index]\n",
    "    par_start = [i + 1 for i in sect_nb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a little reference for my own comfort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # pharm_paragr - this is where the text is\n",
    "    # sect_nb = heading numbers\n",
    "    # par_start = first list item of a paragraph/section\n",
    "    # par_end the last list item of a section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the littlest data frame. The index will not be numerical, we'll use the ingredient names. Subsequently, it won't be possible to access it by .loc[], use .iloc[]\n",
    "I've chosen the columns to be the section names that we scraped previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = ing, columns = sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next came the most brain-farty thing in this whole shebang. I had to make a new list of descriptions. The descriptions had to be merged from the master-list, since one paragraph contained multiple list items. I decided to join the list items by planting back the '\\n'. It will be easier to re-split the list on retrieval (OMG SO EXCITING STAY TUNED FOR WHAT I HAVE IN STORE NEXT).\n",
    "Then the 3 corresponding section descriptors are added in the relevant row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x = []\n",
    "    # makes a list where every list item is a merged description from the master list\n",
    "    for a in range(len(par_start)):\n",
    "        x.append(['\\n '.join(pharm_paragr[par_start[a]:par_end[a]])])\n",
    "    df.iloc[n] = x\n",
    "#this is where the next loop starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful end to a part of a beautiful journey. I'm coming for you beauty industry! Just kidding, I just want to be the hipster who knows what squalene is for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
